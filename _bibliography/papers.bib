@inproceedings{nguyen2022gnninfer,
  abbr = {Submitted},
  author={Thanh-Dat Nguyen* and Thanh Le-Cong and Bach Le and David Lo and ThanhVu H. Nguyen},
  title={Property Inference for Graph Neural Networks}, 
  year={Ongoing},
  organization={SIGPLAN}
}

@inproceedings{widyasari2022xml,
  abbr = {Submitted},
  title={Extreme Multi-Label Learning for Topic Recommendation for GitHub Repositories?},
  author={Ratnadira Widyasari and Zhipeng Zhao and Thanh Le-Cong and Hong Jin Kang and David Lo},
  year={Ongoing},
  organization={IEEE}
}

@inproceedings{le2022invalidator,
  abbr = {Submitted},
  title={Invalidator: Automated Patch Validation via Semantic and Syntactic Reasoning.},
  author={Thanh Le-Cong and Duc Minh Luong and Bach Le and David Lo and Bui, Quang Huy and Tran, Nhat Hoa and Huynh Quyet, Thang},
  booktitle={IEEE Transactions on Software Engineering},
  year={Ongoing},
  organization={IEEE}
}

@inproceedings{nguyen2022midas,
  abbr = {Submitted},
  title={MIDAS: A Multi-granularity Model for Vulnerability-Fixing Commit Classification},
  author={Truong Giang Nguyen and Thanh Le-Cong and Hong Jin Kang and Xu, Bowen and Zhou, Jiayuan and Xia, Xin and Hassan, Ahmed E. and Bach Le and David Lo},
  booktitle={IEEE Transactions on Software Engineering},
  year={Ongoing},
  organization={IEEE}

}

@inproceedings{lyu2022chronos,
  abbr = {Submitted},
  title={Zero-Shot XML for Identification of Libraries from Vulnerability Reports},
  author={Yunbo Lyu and Thanh Le-Cong * and Hong Jin Kang and Ratnadira Widyasari and Zhipeng Zhao and Bach Le and Li, Ming and David Lo},
  year={Ongoing},
  organization={IEEE}

}


@inproceedings{le2022autopruner,
  abbr = {ESEC/FSE},
  title={AutoPruner: Transformer-Based Call Graph Pruning},
  author={Thanh Le-Cong and Hong Jin Kang and Truong Giang Nguyen  and Haryono, Stefanus Agus and David Lo and Bach Le and Huynh Quyet, Thang},
  booktitle={2022 ACM 30th Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Research Track},
  year={2022},
  selected = {true},
  organization={ACM},
  code = {https://github.com/soarsmu/AutoPruner/},
  abstract={Constructing a static call graph requires trade-offs between soundness and precision. Program analysis techniques for constructing call graphs are unfortunately usually imprecise. This paper introduces a novel Transformer-based approach, namely AutoPruner, for eliminating false positives in call graphs via both statistical semantic and structural analysis. Our empirical evaluation on a benchmark dataset of real-world programs shows that AutoPruner can successfully boosts the precision of the call graphs produced by static analysis tools by up to 178% while losing their recall slightly (up to just 24%).},
  pdf={FSE_AutoPruner.pdf},
}

@inproceedings{nguyen2022vulcurator,
  abbr = {ESEC/FSE},
  title={VulCurator: A Vulnerability-Fixing Commit Detector},
  author={Truong Giang Nguyen and Thanh Le-Cong and Hong Jin Kang and Bach Le and David Lo},
  booktitle={2022 ACM 30th Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Tool Demos Track},
  year={2022},
  selected = {true},
  organization={ACM},
  code = {https://github.com/ntgiang71096/VFDetector},
  abstract={Open-source software (OSS) vulnerability management process is important nowadays, as the number of discovered OSS vulnerabilities is increasing over time. Monitoring vulnerability-fixing commits is a part of the standard process to prevent vulnerability exploitation. Manually detecting vulnerability-fixing commits is, however, time consuming due to the possibly large number of commits to review. This paper proposes VulCurator, a tool that leverages deep learning on different sources of information, including commit messages, code changes and issue reports for vulnerability-fixing commit classification. Our experimental results show that VulCurator outperforms the state-of-the-art baselines up to 16.1% in terms of F1-score.},
  pdf={FSE_VulCurator.pdf}

}

@inproceedings{nguyen2022ffl,
  abbr = {ICSME},
  title={FFL: Fine grained Fault Localization for Student Programs via Syntactic and Semantic Reasoning},
  author={Nguyen, Thanh-Dat and  Thanh Le-Cong and  Duc-Minh Luong and  Van-Hai Duong and  Bach Le and  David Lo and  Quyet-Thang Huynh},
  booktitle={2022 IEEE 38th International Conference on Software Maintenance and Evolution, Research Track},
  year={2022},
  selected = {true},
  organization={IEEE},
  code = {https://github.com/FFL2022/FFL},
  abstract={Fault localization has been used to provide feedback for incorrect student programs since locations of faults can be a valuable hint for students about what caused their programs to crash. Unfortunately, existing fault localization techniques for student programs are limited because they usually consider either the program's syntax or semantics alone. This paper introduces FFL (Fine-grained Fault Localization), a novel GNN-based technique using syntactic and semantic reasoning for localizing bugs in student programs. Experimental results show that FFL successfully localizes bug for 84.6% out of 2136 programs on Prutor and 83.1% out of 780 programs on Codeflaws concerning the top-10 suspicious statements },
  pdf={}
}

@inproceedings{nguyen2022gnninfer,
  abbr = {ICSE},
  author={Thanh-Dat Nguyen* and Thanh Le-Cong* and ThanhVu H. Nguyen and Bach Le and Quyet-Thang Huynh},
  booktitle={2022 IEEE/ACM 44th International Conference on Software Engineering: New Ideas and Emerging Results)}, 
  title={Toward the Analysis of Graph Neural Networks}, 
  year={2022},
  volume={},
  number={},
  selected = {true},
  pages={116-120},
  abstract={Graph Neural Networks (GNNs) have recently emerged as a robust framework for graph-structured data. However, unlike other deep neural networks such as Feed Forward Neural Networks (FFNNs), few analyses such as verification and property inferences exist, potentially due to dynamic behaviors of GNNs, which can take arbitrary graphs as input, whereas FFNNs which only take fixed size numerical vectors as inputs. This paper proposes an approach to analyze GNNs by converting them into FFNNs and reusing existing FFNNs analyses. We discuss various designs to ensure the scalability and accuracy of the conversions. We illustrate our method on a study case of node classification. We believe that our approach opens new research directions for understanding and analyzing GNNs.},
  pdf={ICSE_GNNInfer.pdf},
  organization={IEEE}
}

@inproceedings{le2021usability,
  abbr = {ISSRE},
  title={Usability and Aesthetics: Better Together for Automated Repair of Web Pages},
  author={Thanh Le-Cong and Le, Xuan Bach D and Quyet-Thang Huynh and Phi Le Nguyen},
  booktitle={2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE)},
  pages={173--183},
  year={2021},
  selected = {true},
  abstract={With the recent explosive growth of mobile devices such as smartphones or tablets, guaranteeing consistent web appearance across all environments has become a significant problem. This happens simply because it is hard to keep track of the web appearance on different sizes and types of devices that render the web pages. Therefore, fixing the inconsistent appearance of web pages can be difficult, and the cost incurred can be huge, e.g., poor user experience and financial loss due to it. In this paper, we propose an automated repair approach for web pages based on meta-heuristic algorithms that can assure both usability and aesthetics. The key novelty that empowers our approach is a novel fitness function that allows us to optimistically evolve buggy web pages to find the best solution that optimizes both usability and aesthetics at the same time. Empirical evaluations show that our approach is able to successfully resolve mobile-friendly problems in 94% of the evaluation subjects, significantly outperforming state-of-the-art baseline techniques in terms of both usability and aesthetics.},
  pdf={ISSRE21},
  organization={IEEE}
}

@inproceedings{tran2020safl,
  abbr = {ICMLA},
  title={SAFL: A Self-Attention Scene Text Recognizer with Focal Loss},
  author={Tran*, Bao Hieu and Thanh Le-Cong* and Nguyen, Huu Manh and Le, Duc Anh and Nguyen, Thanh Hung and Phi Le Nguyen},
  booktitle={2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  pages={1440--1445},
  year={2020},
  code = {https://github.com/thanhlecongg/SAFL},
  abstract={In the last decades, scene text recognition has gainedworldwide attention from both the academic community andactual users due to its importance in a wide range of applications.Despite achievements in optical character recognition, scenetext recognition remains challenging due to inherent problemssuch as distortions or irregular layout. Most of the existingapproaches mainly leverage recurrence or convolution-basedneural networks. However, while recurrent neural networks(RNNs) usually suffer from slow training speed due to sequentialcomputation and encounter problems as vanishing gradient orbottleneck, CNN endures a trade-off between complexity andperformance. In this paper, we introduce SAFL, a self-attention-based neural network model with the focal loss for scene textrecognition, to overcome the limitation of the existing approaches.The use of focal loss instead of negative log-likelihood helps themodel focus more on low-frequency samples training. Moreover,to deal with the distortions and irregular texts, we exploit SpatialTransformerNetwork (STN) to rectify text before passing to therecognition network. We perform experiments to compare theperformance of the proposed model with seven benchmarks.The numerical results show that our model achieves the bestperformance. (2) (PDF) SAFL: A Self-Attention Scene Text Recognizer with Focal Loss.},
  pdf={ICMLA_SAFL.pdf},
  organization={IEEE}
}

@article{huynh2020multifactorial,
  abbr = {INS},
  title={A Multifactorial Optimization Paradigm for Linkage Tree Genetic Algorithm},
  author={Thi Thanh Binh Huynh and Dinh Thanh Pham and Ba Trung Tran and Thanh Le-Cong and Minh Hai Phong Le and Ananthram Swami and Thu Lam Bui},
  journal={Information Sciences},
  volume={540},
  pages={325--344},
  year={2020},
  code = {https://github.com/thanhlecongg/MFLTGA},
  abstract={Linkage Tree Genetic Algorithm (LTGA) is an effective Evolutionary Algorithm (EA) to solve complex problems using the linkage information between problem variables. LTGA performs well in various kinds of single-task optimization and yields promising results in comparison with the canonical genetic algorithm. However, LTGA is an unsuitable method for dealing with multi-task optimization problems. On the other hand, Multifactorial Optimization (MFO) can simultaneously solve independent optimization problems, which are encoded in a unified representation to take advantage of the process of knowledge transfer. In this paper, we introduce Genetic Algorithm (MF-LTGA) by combining the main features of both LTGA and MFO. MF-LTGA is able to tackle multiple optimization tasks at the same time, each task learns the dependency between problem variables from the shared representation. This knowledge serves to determine the high-quality partial solutions for supporting other tasks in exploring the search space. Moreover, MF-LTGA speeds up convergence because of knowledge transfer of relevant problems. We demonstrate the effectiveness of the proposed algorithm on two benchmark problems: Clustered Shortest-Path Tree Problem and Deceptive Trap Function. In comparison to LTGA and existing methods, MF-LTGA outperforms in quality of the solution or in computation time.},
  pdf={InfSci_MFLTGA.pdf},
  publisher={Elsevier}
}

